{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polyphonic-found",
   "metadata": {},
   "source": [
    "\n",
    "# Machine Translation \n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "In this notebook, I will build a deep neural network that functions as part of an end-to-end machine translation pipeline. My completed pipeline will accept English text as input and return the Persian translation.\n",
    "\n",
    "\n",
    "- **Dataset** - To laod and investigate dataset\n",
    "- **Preprocess** - To convert text to sequence of integers.\n",
    "- **Models** Create models which accepts a sequence of integers as input and returns a probability distribution over possible translations.\n",
    "\n",
    "- **Prediction** Run the model on English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ahead-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.ticker as ticker\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, LSTM, Flatten\n",
    "from tensorflow.keras.layers import Embedding, RepeatVector, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-insertion",
   "metadata": {},
   "source": [
    "### Verify access to the GPU\n",
    "\n",
    "The following test applies only if you expect to be using a GPU and verify that the device_type is \"GPU\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deadly-housing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 11720315345421004392,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 5431029085691602460\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7092450112\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 11175662991275045979\n",
       " physical_device_desc: \"device: 0, name: GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 8836071686770997679\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "tf.python.client.device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gorgeous-roads",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n",
    "#opus.nlpl.eu/download.php?f=TEP/v1/moses/en-fa.txt.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-passage",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "I begin by laoding and investigating the dataset that will be used to train and evaluate my pipeline.  The dataset, used for machine translation are from [manythings](http://www.manythings.org/anki/).  However, that will take a long time to train a neural network on.  I'll be using a dataset, created for this project that contains a small vocabulary.  \n",
    "\n",
    "### Load Data\n",
    "\n",
    "The data is located in `data/pes.txt` . The `pes.txt` file contains English sentences with their Persian translations. Load the English and Persian data from the files from running the cell below. \n",
    "\n",
    "\n",
    "* Each line in the file contains an English sentence with the respective translation in each line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compatible-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_source = \"./data/en-fa/TEP.en-fa.en\"#Read the data\n",
    "data_path_target = \"./data/en-fa/TEP.en-fa.fa\"#Read the data\n",
    "\n",
    "source_lines_raw= pd.read_table(data_path_source,names=['source'],  )\n",
    "source_lines_raw.index.name= \"ID\"\n",
    "\n",
    "target_lines_raw= pd.read_table(data_path_target,names=['target'])\n",
    "target_lines_raw.index.name= \"ID\"\n",
    "\n",
    "traget_source_join = pd.merge(source_lines_raw, target_lines_raw, on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "breathing-pizza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raspy breathing .</td>\n",
       "      <td>صداي خر خر .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dad .</td>\n",
       "      <td>پدر .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maybe its the wind .</td>\n",
       "      <td>شايد صداي باد باشه .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no .</td>\n",
       "      <td>نه .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stop please stop .</td>\n",
       "      <td>دست نگه داريد خواهش ميکنم دست نگه داريد .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611899</th>\n",
       "      <td>zodiac .</td>\n",
       "      <td>بيگانه پرست .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611900</th>\n",
       "      <td>zodiacal light .</td>\n",
       "      <td>اجنبي پرست .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611901</th>\n",
       "      <td>zombi .</td>\n",
       "      <td>دشمن بيگانه .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611902</th>\n",
       "      <td>zombiism .</td>\n",
       "      <td>بيگانه‌ترس .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611903</th>\n",
       "      <td>zonal .</td>\n",
       "      <td>بيگانه ترسي .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>611904 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      source                                     target\n",
       "ID                                                                     \n",
       "0          raspy breathing .                               صداي خر خر .\n",
       "1                      dad .                                      پدر .\n",
       "2       maybe its the wind .                       شايد صداي باد باشه .\n",
       "3                       no .                                       نه .\n",
       "4         stop please stop .  دست نگه داريد خواهش ميکنم دست نگه داريد .\n",
       "...                      ...                                        ...\n",
       "611899              zodiac .                              بيگانه پرست .\n",
       "611900      zodiacal light .                               اجنبي پرست .\n",
       "611901               zombi .                              دشمن بيگانه .\n",
       "611902            zombiism .                               بيگانه‌ترس .\n",
       "611903               zonal .                              بيگانه ترسي .\n",
       "\n",
       "[611904 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traget_source_join#.iloc[457].values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-crash",
   "metadata": {},
   "source": [
    "## 2. Preprocess\n",
    "\n",
    "For this project, I won't use text data as input to your model. Instead, I'll convert the text into sequences of integers using the following preprocess methods:\n",
    "\n",
    "1. Convert word into lowercase\n",
    "2. Clean sentences and Remove punctuaions \n",
    "3. Adding 'start_ ' and  ' _end' at the start and end of the sentences \n",
    "4. Tokenize the words into ids\n",
    "5. Add padding to make all the sequences the same length.\n",
    "\n",
    "Time to start preprocessing the data...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "standard-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_sentence(sentence):  \n",
    "    \n",
    "    num_digits= str.maketrans('','', digits)\n",
    "    \n",
    "    sentence= sentence.lower()\n",
    "    sentence= re.sub(\" +\", \" \", sentence)\n",
    "    sentence= re.sub(\"'\", '', sentence)\n",
    "    sentence= sentence.translate(num_digits)\n",
    "    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.rstrip().strip()\n",
    "    \n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    sentence=  'start ' + sentence + ' end'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "serial-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_frame):\n",
    "    \n",
    "    source = data_frame[\"source\"].map(preprocessing_sentence).values\n",
    "    target = data_frame[\"target\"].map(preprocessing_sentence).values\n",
    "\n",
    "    return source, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "amino-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_traget_source_join = traget_source_join.sample(traget_source_join.shape[0]//25)\n",
    "source, target = create_dataset(sample_traget_source_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "living-physics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences of the source: 24476 \n",
      "Number of sentences of the target: 24476 \n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sentences of the source: {} \".format(len(source)))\n",
    "print(\"Number of sentences of the target: {} \".format(len(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "literary-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['start into the banquet  ,  the monkey king crashed uninvited  . end',\n",
       "       'start of their none too numerous years  . end',\n",
       "       'start if i tell you about them ,  you have no idea what hell do . end',\n",
       "       ..., 'start the new governor has arrived . end',\n",
       "       'start madam ! end', 'start why was i lied before sorry  . end'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "postal-apollo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['start پادشاه ميمون ناخوانده وارد مهماني شد  . end',\n",
       "       'start دوره\\u200cي خود را ديده بودند  . end',\n",
       "       'start نتونستيد بالونم رو پيدا كنيد ؟ آره  .  پيداش كرديم end',\n",
       "       ..., 'start خفه شو ! end',\n",
       "       'start یانگوم درباره این موضوع نباید صحبتی بکند end',\n",
       "       'start چرا قبلا دروغ گفتيد متاسفم  . end'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-prophet",
   "metadata": {},
   "source": [
    "### Tokenize \n",
    "\n",
    "For a neural network to predict on text data, it first has to be turned into data it can understand. Text data like \"dog\" is a sequence of ASCII character encodings.  Since a neural network is a series of multiplication and addition operations, the input data needs to be number(s).\n",
    "\n",
    "We can turn each character into a number or each word into a number.  These are called character and word ids, respectively.  Character ids are used for character level models that generate text predictions for each character.  A word level model uses word ids that generate text predictions for each word.  Word level models tend to learn better, since they are lower in complexity.\n",
    "\n",
    "I turn each sentence into a sequence of words ids using Keras's [`Tokenizer`](https://keras.io/preprocessing/text/#tokenizer) function. I use this function to tokenize `english_sentences` and `persian_sentences` in the cell below.\n",
    "\n",
    "\n",
    "### Padding \n",
    "\n",
    "When batching the sequence of word ids together, each sequence needs to be the same length.  Since sentences are dynamic in length, we can add padding **to the end** of the sequences to make them the same length.\n",
    "\n",
    "To make sure all the English sequences have the same length and all the Persian sequences have the same length by adding padding to the **end** of each sequence using Keras's [`pad_sequences`](https://keras.io/preprocessing/sequence/#pad_sequences) function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fewer-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tokenizer for source sentence\n",
    "\n",
    "source_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters = \" \")# Fit the source sentences to the source tokenizer\n",
    "source_sentence_tokenizer.fit_on_texts(source)\n",
    "source_tensor = source_sentence_tokenizer.texts_to_sequences(source)\n",
    "\n",
    "#Sequences that are shorter, padded with 0 at the end.\n",
    "source_tensor = tf.keras.preprocessing.sequence.pad_sequences(source_tensor,padding='post' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "apparent-gender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24476, 29)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "worse-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the target sentence tokenizer\n",
    "\n",
    "target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters = \" \")# Fit the tokenizer on target sentences\n",
    "target_sentence_tokenizer.fit_on_texts(target)#conver target text to sequnec of integers\n",
    "target_tensor = target_sentence_tokenizer.texts_to_sequences(target)# Post pad the shorter sequences with 0\n",
    "\n",
    "target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor,padding='post', maxlen=source_tensor.shape[1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "amazing-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24476, 29)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "continuous-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the source and target to work with a basic GRU\n",
    "\n",
    "source_tensor = source_tensor.reshape((-1, source_tensor.shape[1], 1))\n",
    "target_tensor = target_tensor.reshape((-1, target_tensor.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "significant-cleaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the source: (24476, 29, 1) \n",
      "The shape of the target: (24476, 29, 1) \n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the source: {} \".format(source_tensor.shape))\n",
    "print(\"The shape of the target: {} \".format(target_tensor.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "apparent-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_text(source, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn sequence from a Ids into text using the tokenizer\n",
    "    :param source: sequence aof IDs\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the IDs\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[s] for s in source])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "advance-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "Sequence number is 6406 \n",
      "\n",
      " English Input:  start australem means south . and then . . . end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      " Persian Output: start گفته که اونجا آدمي زندگي مي کنه end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "random_id =  np.random.randint(0, high=source_tensor.shape[0])\n",
    "for i in range(random_id,random_id+1):\n",
    "    print(\"---------------------------------------------------------------------------------------------------\")\n",
    "    print('Sequence number is {} '.format(i + 1))\n",
    "    print()\n",
    "    print(' English Input:  {}'.format(to_text(source_tensor[i,:,0], source_sentence_tokenizer)))\n",
    "    print()\n",
    "    print(' Persian Output: {}'.format(to_text(target_tensor[i,:,0], target_sentence_tokenizer)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-nature",
   "metadata": {},
   "source": [
    "### Split into Train and Test\n",
    "\n",
    "Split the dataset into a test and train. 80% of data is used for training and 20% for testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "technical-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_tensor, source_test_tensor, target_train_tensor, target_test_tensor= train_test_split(source_tensor, target_tensor,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "enabling-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#That + 1 is because of reserving padding ( index zero)\n",
    "source_vocab_size= len(source_sentence_tokenizer.word_index)+1\n",
    "target_vocab_size= len(target_sentence_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "reported-manchester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the source vocabulary: 14209\n",
      "Size of the target vocabulary: 20950\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the source vocabulary: {}\".format(source_vocab_size))\n",
    "print(\"Size of the target vocabulary: {}\".format(target_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cooperative-negative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the source train tensor: (19580, 29, 1) \n",
      "The shape of the target train tensor: (19580, 29, 1) \n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the source train tensor: {} \".format(source_train_tensor.shape))\n",
    "print(\"The shape of the target train tensor: {} \".format(target_train_tensor.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "listed-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the source test tensor: (4896, 29, 1) \n",
      "The shape of the target test tensor: (4896, 29, 1) \n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the source test tensor: {} \".format(source_test_tensor.shape))\n",
    "print(\"The shape of the target test tensor: {} \".format(target_test_tensor.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-roulette",
   "metadata": {},
   "source": [
    "## 3. Models\n",
    "In this section, I will experiment with various neural network architectures.\n",
    "I will begin by training four relatively simple architectures.\n",
    "- Model 1 is a simple GRU\n",
    "- Model 2 is a GRU with Embedding\n",
    "- Model 3 is a Bidirectional GRU\n",
    "- Model 4 is an Encoder-Decoder GRU\n",
    "\n",
    "After experimenting with the four simple architectures, I will construct a deeper architecture that is designed to outperform all four models which uses Attention mechanism.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-homework",
   "metadata": {},
   "source": [
    "### Model 1: GRU\n",
    "![RNN](./images/rnn.png)\n",
    "A basic RNN model is a good baseline for sequence data.  In this model, you'll build a GRU that translates English to Persian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "primary-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(input_shape, english_vocab_size, persian_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a basic RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    #Build the layers\n",
    "    learning_rate = 0.009    \n",
    "    \n",
    "    inputs = Input(shape=(input_shape[1:]))\n",
    "    gru = GRU(1024, input_shape=inputs.shape[1:], return_sequences=True)(inputs)\n",
    "    logits = TimeDistributed(Dense(persian_vocab_size, activation=\"softmax\"))(gru)\n",
    "    \n",
    "    model = Model(inputs, logits)\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dutch-cemetery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 29, 1)]           0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 29, 1024)          3154944   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 29, 20950)         21473750  \n",
      "=================================================================\n",
      "Total params: 24,628,694\n",
      "Trainable params: 24,628,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the neural network\n",
    "simple_model = simple_model(source_train_tensor.shape,\n",
    "                            source_vocab_size,\n",
    "                            target_vocab_size)\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "handed-african",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 - 37s - loss: 2.5168 - accuracy: 0.7088 - val_loss: 2.2047 - val_accuracy: 0.7201\n",
      "Epoch 2/10\n",
      "123/123 - 18s - loss: 2.1030 - accuracy: 0.7212 - val_loss: 2.1408 - val_accuracy: 0.7225\n",
      "Epoch 3/10\n",
      "123/123 - 17s - loss: 2.0201 - accuracy: 0.7227 - val_loss: 2.1453 - val_accuracy: 0.7228\n",
      "Epoch 4/10\n",
      "123/123 - 17s - loss: 1.9697 - accuracy: 0.7232 - val_loss: 2.1555 - val_accuracy: 0.7221\n",
      "Epoch 5/10\n",
      "123/123 - 17s - loss: 1.9229 - accuracy: 0.7236 - val_loss: 2.1556 - val_accuracy: 0.7233\n",
      "Epoch 6/10\n",
      "123/123 - 17s - loss: 1.8769 - accuracy: 0.7240 - val_loss: 2.1727 - val_accuracy: 0.7233\n",
      "Epoch 7/10\n",
      "123/123 - 17s - loss: 1.8316 - accuracy: 0.7241 - val_loss: 2.1884 - val_accuracy: 0.7236\n",
      "Epoch 8/10\n",
      "123/123 - 17s - loss: 1.7871 - accuracy: 0.7241 - val_loss: 2.2072 - val_accuracy: 0.7233\n",
      "Epoch 9/10\n",
      "123/123 - 17s - loss: 1.7454 - accuracy: 0.7243 - val_loss: 2.2364 - val_accuracy: 0.7222\n",
      "Epoch 10/10\n",
      "123/123 - 17s - loss: 1.7039 - accuracy: 0.7249 - val_loss: 2.2397 - val_accuracy: 0.7225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f68724ac950>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(source_train_tensor,target_train_tensor, batch_size=128, epochs=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-mustang",
   "metadata": {},
   "source": [
    "### Evaluate Model on test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "graphic-overall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 2s 96ms/step - loss: 2.2359 - accuracy: 0.7234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.235947370529175, 0.7234406471252441]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.evaluate(source_test_tensor,target_test_tensor, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-election",
   "metadata": {},
   "source": [
    "\n",
    "### Ids Back to Text\n",
    "\n",
    "The neural network will be translating the input to words ids, which isn't the final form we want.  We want the French translation.  The function `logits_to_text` will bridge the gab between the logits from the neural network to the Persian translation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "polish-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_text(logits,ground_true, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "    \n",
    "    prediction = ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "    ground_true = ' '.join([index_to_words[t[0]]  for t in ground_true[0]])\n",
    "\n",
    "    print()\n",
    "    print(\"The prediction is:\\n\\n {}\".format(prediction))\n",
    "    print()\n",
    "    print(\"The prediction should be:\\n\\n {}\".format(ground_true))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-large",
   "metadata": {},
   "source": [
    "### Make Prediction using the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "recent-subject",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction(s)...\n",
      "\n",
      "The input sequence is:\n",
      "\n",
      " start i got him . end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "The prediction is:\n",
      "\n",
      " start من به . . end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "The prediction should be:\n",
      "\n",
      " start من اونو ميارم . end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (\"prediction(s)...\")\n",
    "print()\n",
    "\n",
    "random_id =  np.random.randint(0, high=source_test_tensor.shape[0])\n",
    "test = source_test_tensor[random_id:random_id+1]\n",
    "ground_truth = target_test_tensor[random_id:random_id+1]\n",
    "\n",
    "\n",
    "print(\"The input sequence is:\\n\\n {}\".format(to_text(test[0,:,0], source_sentence_tokenizer)))\n",
    "\n",
    "print(logits_to_text(simple_model.predict(test)[0], ground_truth ,target_sentence_tokenizer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-killing",
   "metadata": {},
   "source": [
    "### Model 2: Embedding \n",
    "![RNN](./images/embedding.png)\n",
    "I've turned the words into ids, but there's a better representation of a word.  This is called word embeddings.  An embedding is a vector representation of the word that is close to similar words in n-dimensional space, where the n represents the size of the embedding vectors.\n",
    "\n",
    "In this model, you'll create a GRU model using embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "noble-permission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 29, 256)           3637504   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 29, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 29, 20950)         21473750  \n",
      "=================================================================\n",
      "Total params: 29,049,558\n",
      "Trainable params: 29,049,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def embed_model(input_shape, english_vocab_size, persian_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a RNN model using word embedding on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    learning_rate =  0.009    \n",
    "    inputs = Input(input_shape[1:])\n",
    "    embedding = Embedding(english_vocab_size, 256)(inputs)\n",
    "    gru = GRU(1024, return_sequences=True)(embedding)\n",
    "    logits = TimeDistributed(Dense(persian_vocab_size, activation=\"softmax\"))(gru)\n",
    "    \n",
    "    model = Model(inputs, logits)\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reshaping the input to work with the model\n",
    "reshaped_source_train_tensor = source_train_tensor.reshape((-1, source_train_tensor.shape[-2]))\n",
    "\n",
    "\n",
    "# Train the neural network\n",
    "embedding_model = embed_model(reshaped_source_train_tensor.shape,\n",
    "                              source_vocab_size,\n",
    "                              target_vocab_size)\n",
    "embedding_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "yellow-bidder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 - 20s - loss: 2.2957 - accuracy: 0.7147 - val_loss: 2.0568 - val_accuracy: 0.7262\n",
      "Epoch 2/10\n",
      "123/123 - 20s - loss: 2.8797 - accuracy: 0.7121 - val_loss: 3.4447 - val_accuracy: 0.7194\n",
      "Epoch 3/10\n",
      "123/123 - 20s - loss: 3.4138 - accuracy: 0.7244 - val_loss: 3.4570 - val_accuracy: 0.7035\n",
      "Epoch 4/10\n",
      "123/123 - 20s - loss: 3.3872 - accuracy: 0.7271 - val_loss: 3.4183 - val_accuracy: 0.7159\n",
      "Epoch 5/10\n",
      "123/123 - 20s - loss: 3.3650 - accuracy: 0.7320 - val_loss: 3.4228 - val_accuracy: 0.7155\n",
      "Epoch 6/10\n",
      "123/123 - 20s - loss: 3.3602 - accuracy: 0.7334 - val_loss: 3.4164 - val_accuracy: 0.7231\n",
      "Epoch 7/10\n",
      "123/123 - 20s - loss: 3.3495 - accuracy: 0.7362 - val_loss: 3.4206 - val_accuracy: 0.7163\n",
      "Epoch 8/10\n",
      "123/123 - 20s - loss: 3.3509 - accuracy: 0.7364 - val_loss: 3.4309 - val_accuracy: 0.7150\n",
      "Epoch 9/10\n",
      "123/123 - 20s - loss: 3.3435 - accuracy: 0.7381 - val_loss: 3.4297 - val_accuracy: 0.7230\n",
      "Epoch 10/10\n",
      "123/123 - 20s - loss: 3.3339 - accuracy: 0.7402 - val_loss: 3.4240 - val_accuracy: 0.7207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f686c1adf10>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.fit(reshaped_source_train_tensor, target_train_tensor, batch_size=128, epochs=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-general",
   "metadata": {},
   "source": [
    "### Evaluate Model on test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "quiet-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 2s 97ms/step - loss: 3.4266 - accuracy: 0.7213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.426565170288086, 0.7212995886802673]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping the input to work with the model\n",
    "reshaped_source_test_tensor = source_test_tensor.reshape((-1, source_test_tensor.shape[-2]))\n",
    "\n",
    "embedding_model.evaluate(reshaped_source_test_tensor, target_test_tensor, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-north",
   "metadata": {},
   "source": [
    "### Make Prediction using the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abstract-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction(s)...\n",
      "\n",
      "The input sequence is:\n",
      "\n",
      " start its related to the captains story . end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "The prediction is:\n",
      "\n",
      " start اين در . در end . end end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "The prediction should be:\n",
      "\n",
      " start اما به خاطر شكستي كه خوردند الان در موقعيت بدي هستند end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (\"prediction(s)...\")\n",
    "print()\n",
    "\n",
    "random_id =  np.random.randint(0, high=source_test_tensor.shape[0])\n",
    "\n",
    "test = source_test_tensor[random_id:random_id+1]\n",
    "ground_truth = target_test_tensor[random_id:random_id+1]\n",
    "\n",
    "\n",
    "print(\"The input sequence is:\\n\\n {}\".format(to_text(test[0,:,0], source_sentence_tokenizer)))\n",
    "\n",
    "print(logits_to_text(embedding_model.predict(test)[0],ground_truth ,target_sentence_tokenizer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-cargo",
   "metadata": {},
   "source": [
    "### Model 3: Bidirectional GRus\n",
    "![RNN](./images/bidirectional.png)\n",
    "\n",
    "One restriction of a RNN is that it can't see the future input, only the past.  This is where bidirectional recurrent neural networks come in.  They are able to see the future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "significant-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bd_model(input_shape, english_vocab_size, persian_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a bidirectional RNN model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    learning_rate =  0.009\n",
    "    \n",
    "    inputs = Input(shape=input_shape[1:])\n",
    "    embedding = Embedding(english_vocab_size, 256)(inputs)\n",
    "    bidirectional = Bidirectional(GRU(1024, return_sequences=True))(embedding)\n",
    "    logits = TimeDistributed(Dense(persian_vocab_size, activation=\"softmax\"))(bidirectional)\n",
    "    \n",
    "    model = Model(inputs, logits)\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    \n",
    "#tests.test_bd_model(bd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "complicated-louis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 29, 256)           3637504   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 29, 2048)          7876608   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 29, 20950)         42926550  \n",
      "=================================================================\n",
      "Total params: 54,440,662\n",
      "Trainable params: 54,440,662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "bidirectioanl_model = bd_model(reshaped_source_train_tensor.shape,\n",
    "                              source_vocab_size,\n",
    "                              target_vocab_size)\n",
    "bidirectioanl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "twenty-relief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 - 42s - loss: 4.7380 - accuracy: 0.6957 - val_loss: 4.6009 - val_accuracy: 0.7146\n",
      "Epoch 2/10\n",
      "123/123 - 41s - loss: 4.6096 - accuracy: 0.7140 - val_loss: 4.5997 - val_accuracy: 0.7146\n",
      "Epoch 3/10\n",
      "123/123 - 41s - loss: 4.6095 - accuracy: 0.7141 - val_loss: 4.5999 - val_accuracy: 0.7146\n",
      "Epoch 4/10\n",
      "123/123 - 41s - loss: 4.6099 - accuracy: 0.7140 - val_loss: 4.6002 - val_accuracy: 0.7147\n",
      "Epoch 5/10\n",
      "123/123 - 41s - loss: 4.6098 - accuracy: 0.7140 - val_loss: 4.5999 - val_accuracy: 0.7146\n",
      "Epoch 6/10\n",
      "123/123 - 41s - loss: 4.6092 - accuracy: 0.7141 - val_loss: 4.5995 - val_accuracy: 0.7147\n",
      "Epoch 7/10\n",
      "123/123 - 41s - loss: 4.6096 - accuracy: 0.7140 - val_loss: 4.5999 - val_accuracy: 0.7147\n",
      "Epoch 8/10\n",
      "123/123 - 41s - loss: 4.6093 - accuracy: 0.7141 - val_loss: 4.5996 - val_accuracy: 0.7147\n",
      "Epoch 9/10\n",
      "123/123 - 41s - loss: 4.6092 - accuracy: 0.7141 - val_loss: 4.5995 - val_accuracy: 0.7147\n",
      "Epoch 10/10\n",
      "123/123 - 41s - loss: 4.6095 - accuracy: 0.7141 - val_loss: 4.6008 - val_accuracy: 0.7147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f684c1075d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidirectioanl_model.fit(reshaped_source_train_tensor, target_train_tensor, batch_size=128, epochs=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-bandwidth",
   "metadata": {},
   "source": [
    "### Evaluate Model on test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "isolated-finder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 140ms/step - loss: 4.6137 - accuracy: 0.7139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.613731861114502, 0.7138691544532776]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidirectioanl_model.evaluate(reshaped_source_test_tensor, target_test_tensor, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-grade",
   "metadata": {},
   "source": [
    "### Make Prediction using the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "former-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction(s)...\n",
      "\n",
      "The input sequence is:\n",
      "\n",
      " start theres something i want to say . end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "The prediction is:\n",
      "\n",
      " start بله <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "The prediction should be:\n",
      "\n",
      " start يه چيزي ميخواستم بگم . end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (\"prediction(s)...\")\n",
    "print()\n",
    "\n",
    "random_id =  np.random.randint(0, high=source_test_tensor.shape[0])\n",
    "\n",
    "test = source_test_tensor[random_id:random_id+1]\n",
    "ground_truth = target_test_tensor[random_id:random_id+1]\n",
    "\n",
    "\n",
    "print(\"The input sequence is:\\n\\n {}\".format(to_text(test[0,:,0], source_sentence_tokenizer)))\n",
    "\n",
    "print(logits_to_text(bidirectioanl_model.predict(test)[0],ground_truth ,target_sentence_tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-elite",
   "metadata": {},
   "source": [
    "### Model 4: Encoder-Decoder\n",
    "\n",
    "Time to look at encoder-decoder models.  This model is made up of an encoder and decoder. The encoder creates a matrix representation of the sentence.  The decoder takes this matrix as input and predicts the translation as output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "norwegian-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encdec_model(input_shape, output_sequence_length, english_vocab_size, persian_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train an encoder-decoder model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    learning_rate =  0.008\n",
    "    \n",
    "    inputs = Input(shape=input_shape[1:])\n",
    "    embedding = Embedding(english_vocab_size, 128)(inputs)\n",
    "    \n",
    "    enocder = Bidirectional(GRU(128, return_sequences=True))(embedding)\n",
    "\n",
    "\n",
    "    #flatt = Flatten()(enocder)\n",
    "    #repeated_vector  = RepeatVector(output_sequence_length)(flatt)\n",
    "    \n",
    "    decoder =  GRU(512, return_sequences=True)(enocder)\n",
    "    decoder = TimeDistributed(Dense(persian_vocab_size, activation=\"softmax\"))(decoder)\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Model(inputs, decoder)\n",
    "    \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#tests.test_encdec_model(encdec_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "distant-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 29, 128)           1818752   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 29, 256)           198144    \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 29, 512)           1182720   \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 29, 20950)         10747350  \n",
      "=================================================================\n",
      "Total params: 13,946,966\n",
      "Trainable params: 13,946,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "encoder_decoder_model = encdec_model(reshaped_source_train_tensor.shape,\n",
    "                                     reshaped_source_train_tensor.shape[1],\n",
    "                                      source_vocab_size,\n",
    "                                      target_vocab_size)\n",
    "encoder_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "opened-ground",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "245/245 - 21s - loss: 2.6925 - accuracy: 0.7159 - val_loss: 2.5795 - val_accuracy: 0.7220\n",
      "Epoch 2/10\n",
      "245/245 - 20s - loss: 2.2282 - accuracy: 0.7244 - val_loss: 2.1437 - val_accuracy: 0.7184\n",
      "Epoch 3/10\n",
      "245/245 - 20s - loss: 2.0050 - accuracy: 0.7312 - val_loss: 2.1387 - val_accuracy: 0.7250\n",
      "Epoch 4/10\n",
      "245/245 - 20s - loss: 1.9216 - accuracy: 0.7371 - val_loss: 2.1404 - val_accuracy: 0.7264\n",
      "Epoch 5/10\n",
      "245/245 - 20s - loss: 1.8445 - accuracy: 0.7420 - val_loss: 2.1640 - val_accuracy: 0.7232\n",
      "Epoch 6/10\n",
      "245/245 - 20s - loss: 1.7475 - accuracy: 0.7462 - val_loss: 2.1875 - val_accuracy: 0.7160\n",
      "Epoch 7/10\n",
      "245/245 - 20s - loss: 1.6709 - accuracy: 0.7489 - val_loss: 2.2398 - val_accuracy: 0.7177\n",
      "Epoch 8/10\n",
      "245/245 - 20s - loss: 1.5898 - accuracy: 0.7522 - val_loss: 2.2723 - val_accuracy: 0.7180\n",
      "Epoch 9/10\n",
      "245/245 - 20s - loss: 1.5177 - accuracy: 0.7550 - val_loss: 2.3014 - val_accuracy: 0.7196\n",
      "Epoch 10/10\n",
      "245/245 - 20s - loss: 1.4283 - accuracy: 0.7601 - val_loss: 2.3397 - val_accuracy: 0.7141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f67e0d96990>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder_model.fit(reshaped_source_train_tensor, target_train_tensor, batch_size=64, epochs=10, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-briefs",
   "metadata": {},
   "source": [
    "### Evaluate Model on test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "decent-healing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 35ms/step - loss: 2.3317 - accuracy: 0.7162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.331676483154297, 0.7161651849746704]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder_model.evaluate(reshaped_source_test_tensor, target_test_tensor, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-ceiling",
   "metadata": {},
   "source": [
    "### Make Prediction using the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "coated-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction(s)...\n",
      "\n",
      "The input sequence is:\n",
      "\n",
      " start hi , mr . fleming . end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "The prediction is:\n",
      "\n",
      " start سلام ، ريک ، . end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      "The prediction should be:\n",
      "\n",
      " start سلام آقاى فلمينگ . end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (\"prediction(s)...\")\n",
    "print()\n",
    "\n",
    "random_id =  np.random.randint(0, high=source_test_tensor.shape[0])\n",
    "\n",
    "test = source_test_tensor[random_id:random_id+1]\n",
    "ground_truth = target_test_tensor[random_id:random_id+1]\n",
    "\n",
    "\n",
    "print(\"The input sequence is:\\n\\n {}\".format(to_text(test[0,:,0], source_sentence_tokenizer)))\n",
    "\n",
    "print(logits_to_text(encoder_decoder_model.predict(test)[0],ground_truth ,target_sentence_tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-weather",
   "metadata": {},
   "source": [
    "### Model 4: Encoder Decoder with Attention mechanism \n",
    "\n",
    "![Attention](./images/attention.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "helpful-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size= batch_size\n",
    "        self.encoder_units=encoder_units\n",
    "        self.embedding=tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru= tf.keras.layers.GRU(encoder_units, \n",
    "                                      return_sequences=True,\n",
    "                                      return_state=True,                                      \n",
    "                                      recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "    def call(self, x, hidden):\n",
    "        #pass the input x to the embedding layer\n",
    "        x= self.embedding(x)\n",
    "        # pass the embedding and the hidden state to GRU\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoder_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "residential-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        \n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "exceptional-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \n",
    "        # hidden state shape == (batch_size, hidden size)\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ahead-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "refined-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        # enc_output (batch_size, max?_lenght, encoder_units) ,enc_hidden (batch_size, encoder_units)\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden) \n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        # dec_input(batch_size, 1)\n",
    "        dec_input = tf.expand_dims( [target_sentence_tokenizer.word_index['start']] * BATCH_SIZE, 1) \n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            \n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            \n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "             # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fabulous-season",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "brown-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19580, 29)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_source_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "trying-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "rehsaped_target_train_tensor = target_train_tensor.reshape((-1, target_train_tensor.shape[1]))\n",
    "\n",
    "\n",
    "#setting the BATCH SIZE\n",
    "BATCH_SIZE = 64\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "\n",
    "#Create data in memeory \n",
    "dataset=tf.data.Dataset.from_tensor_slices((reshaped_source_train_tensor, rehsaped_target_train_tensor)).shuffle(BATCH_SIZE)# shuffles the data in the batch\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "adapted-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(source_vocab_size, embedding_dim=embedding_dim ,  encoder_units=units,  batch_size =BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "grand-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder= Decoder(vocab_size= target_vocab_size , embedding_dim=embedding_dim, dec_units=units, batch_sz =BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "electrical-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './encode_dcoder_attention_training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "combined-layout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.1586\n",
      "Epoch 1 Batch 100 Loss 0.1238\n",
      "Epoch 1 Batch 200 Loss 0.1984\n",
      "Epoch 1 Batch 300 Loss 0.1195\n",
      "Epoch 1 Loss 0.1397\n",
      "Time taken for 1 epoch 56.792092084884644 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.1470\n",
      "Epoch 2 Batch 100 Loss 0.1209\n",
      "Epoch 2 Batch 200 Loss 0.1618\n",
      "Epoch 2 Batch 300 Loss 0.1199\n",
      "Epoch 2 Loss 0.1294\n",
      "Time taken for 1 epoch 57.468533992767334 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.1318\n",
      "Epoch 3 Batch 100 Loss 0.0990\n",
      "Epoch 3 Batch 200 Loss 0.1717\n",
      "Epoch 3 Batch 300 Loss 0.0947\n",
      "Epoch 3 Loss 0.1250\n",
      "Time taken for 1 epoch 57.067235231399536 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.1428\n",
      "Epoch 4 Batch 100 Loss 0.1102\n",
      "Epoch 4 Batch 200 Loss 0.1071\n",
      "Epoch 4 Batch 300 Loss 0.0920\n",
      "Epoch 4 Loss 0.1197\n",
      "Time taken for 1 epoch 57.55889272689819 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1231\n",
      "Epoch 5 Batch 100 Loss 0.1107\n",
      "Epoch 5 Batch 200 Loss 0.1051\n",
      "Epoch 5 Batch 300 Loss 0.1047\n",
      "Epoch 5 Loss 0.1077\n",
      "Time taken for 1 epoch 58.72194170951843 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0898\n",
      "Epoch 6 Batch 100 Loss 0.1026\n",
      "Epoch 6 Batch 200 Loss 0.1051\n",
      "Epoch 6 Batch 300 Loss 0.0975\n",
      "Epoch 6 Loss 0.0993\n",
      "Time taken for 1 epoch 59.62758827209473 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1053\n",
      "Epoch 7 Batch 100 Loss 0.0814\n",
      "Epoch 7 Batch 200 Loss 0.1229\n",
      "Epoch 7 Batch 300 Loss 0.1386\n",
      "Epoch 7 Loss 0.1107\n",
      "Time taken for 1 epoch 57.26992869377136 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1062\n",
      "Epoch 8 Batch 100 Loss 0.1079\n",
      "Epoch 8 Batch 200 Loss 0.1370\n",
      "Epoch 8 Batch 300 Loss 0.1386\n",
      "Epoch 8 Loss 0.1204\n",
      "Time taken for 1 epoch 57.830554723739624 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1048\n",
      "Epoch 9 Batch 100 Loss 0.1699\n",
      "Epoch 9 Batch 200 Loss 0.2346\n",
      "Epoch 9 Batch 300 Loss 0.1610\n",
      "Epoch 9 Loss 0.1440\n",
      "Time taken for 1 epoch 57.48631954193115 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1419\n",
      "Epoch 10 Batch 100 Loss 0.0729\n",
      "Epoch 10 Batch 200 Loss 0.1815\n",
      "Epoch 10 Batch 300 Loss 0.0950\n",
      "Epoch 10 Loss 0.1266\n",
      "Time taken for 1 epoch 77.72252655029297 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "steps_per_epoch = len(source_train_tensor)//BATCH_SIZE\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                       batch,\n",
    "                                                       batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-catalyst",
   "metadata": {},
   "source": [
    "### Make Prediction using the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "consecutive-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(sentences, source_sentence_tokenizer = source_sentence_tokenizer, target_sentence_tokenizer = target_sentence_tokenizer):\n",
    "    \n",
    "    \n",
    "    max_length =  source_train_tensor.shape[1]\n",
    "    attention_plot = np.zeros((max_length, max_length))\n",
    "\n",
    "    \n",
    "\n",
    "    sentence = preprocessing_sentence(sentences)\n",
    "    inputs = [source_sentence_tokenizer.word_index[w] for w in sentences.split(\" \")]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen =  max_length, padding = \"post\")\n",
    "    \n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = \" \"\n",
    "    \n",
    "    hidden =  [tf.zeros((1, units))]\n",
    "    \n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    \n",
    "    dec_hidden =  enc_hidden\n",
    "    dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start']], 0)\n",
    "    \n",
    "    for t in range(max_length):\n",
    "        \n",
    "        predictions, dec_hidden, attention_weights  =  decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        #storing the attention weights to plot later on\n",
    "\n",
    "        attention_weights =  tf.reshape(attention_weights,(-1, ))\n",
    "        attention_plot [t] = attention_weights.numpy()\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        \n",
    "        \n",
    "        result += target_sentence_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if target_sentence_tokenizer.index_word[predicted_id] == 'end':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot   \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "threatened-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize= (10,10) )\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.matshow(attention, cmap = \"viridis\")\n",
    "    \n",
    "    fontdict = {\"fontsize\":14}\n",
    "    ax.set_xticklabels([\" \"]+sentence, fontdict= fontdict, rotation= 90, )\n",
    "    ax.set_yticklabels([\" \"]+predicted_sentence, fontdict= fontdict,)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "individual-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    \n",
    "    result, sentence, attention_plot  = evaluate(sentence)\n",
    "    \n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "numeric-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_id =  np.random.randint(0, high=source_test_tensor.shape[0])\n",
    "\n",
    "sentence = []\n",
    "for i in source_test_tensor[random_id,:,:]:\n",
    "    if i[0]== 0:\n",
    "        break\n",
    "    sentence.append(source_sentence_tokenizer.index_word[i[0]])\n",
    "sentence = ' '.join(sentence[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "acoustic-soldier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence is:  how can i understand your predicament . . .\n",
      "Persian Ground Truth is::  start چیزی شده؟ end <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence is: \",sentence)\n",
    "print('Persian Ground Truth is::  {}'.format(to_text(target_test_tensor[random_id,:,0], target_sentence_tokenizer)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "southern-technique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: start how can i understand your predicament  .   .   . end\n",
      "Predicted translation:  اين معجزه ، بازي نيست . end \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rima/anaconda3/envs/ESFP/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n",
      "/home/rima/anaconda3/envs/ESFP/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAGrCAYAAABNHNqVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAArp0lEQVR4nO3deZwldX3u8c8zCwyLyI7sroBLROO4XbcgIi6RJC5JXBDUSBSjovFqXOEmEnfjkkQkiWKucbmiuMcEFTWuEYgBo4iyioDsOwOzfO8fVd1zaHsW6NNVp2s+79frvLq7qvrU091npp/+VdWvUlVIkiRp4VvUdwBJkiSNh8VOkiRpICx2kiRJA2GxkyRJGgiLnSRJ0kBY7CRJkgbCYidJkjQQFjtJkqSBsNhJkiQNhMVOUq+SPDfJ5rMs3yzJc/vIJEkLVbylmKQ+JVkN7FpVl81YvgNwWVUt7ieZJC08jthJ6luA2f7C3Au4tuMskrSgLek7gKRNU5IzaQpdAd9Msmpk9WJgb+DLfWSTpIXKYiepLye2b+8HfAm4YWTdrcD5wKc7ziRJC5rn2EnqVZLDgE9W1Yq+s0jSQmexkzQxkmzLjHN/q+qqftJI0sLjoVhJvUqyN3Ac8DvAZqOraM6/86pYSdpIFjtJffswsC3wAuBiZr9CVpK0ETwUK82jJHtt7LZVdeF8ZplUSW4AHlZVP+47iyQtdI7YSfPrfDZ+BGpTPeR4HvAbd56QJN1+Fjtpfj145P19gLfTnE/2vXbZw4E/BV7Tca5J8nLgLUmOrKpf9B1GkhYyD8VKHUnyTeD9VXXijOVPB15eVY/qJ1m/klxPM2K3GLgFGJ2omKrapo9ckrQQOWIndechwBmzLD8DeFDHWSbJn/UdQJKGwhE7qSNJfgr8W1UdNWP5e4CDq+refeSSJA2HxU7qSJInACcBFwDfbxc/FLgr8NSq+teeovUuyS7AocA9gDdW1RVJHgFcXFXn9ZtOkhYOi53UoSR7AEcC+7WLfgocV1W/7C9Vv5I8CPgazdWx9wX2q6pzkxwD7FNVz+oznyQtJBY7Sb1Kcgrwrao6ur2QYv+22D0c+ERV7d1zRElaMLx4QupQki2BBwA785v3RP1MH5kmwINo7jox0yXALh1nkaQFzWIndSTJ44CPAzvMsnpTvifqzcB2syzfD7is4yyStKAt2vAmksbkvcCXgD2qatGMx6Za6gA+BxydZOruE5XkrsDbgE/3lkqSFiDPsZM6kuRG4P5VdU7fWSZJkm2ALwP3B7YCLqU5BPsd4ElVdWOP8SRpQfFQrNSd7wD7Aha7EVV1HfDIJI8FfpvmSMLpVfXVfpNJ0sLjiJ3UkSRPBd4MvBs4E1g5ur6qTu8jlyRpOCx2UkeSrFnP6tqUz7NL8kDgAGa/WvjVvYSSpAXIQ7FSd+7Wd4BJlOTVwFtp7sjxa5orhKf4l6ck3Q6O2EnqVZJLgGOq6oN9Z5Gkhc4RO6lDSZYADwH2AjYbXVdV/9xLqP4tormlmCRpjhyxkzqSZD/gCzSHZAOspvnjaiVwS1Vt02O83rT3hF1aVa/vO4skLXQWO6kjSb4CXENz+6xLaW4tdmfgA8Abqurk3sL1KElo5rG7C/BjfvNq4ef3kUuSFiIPxUrdeTDwmKq6sb1CdklVnd5ePPB+mgl6N0XHAo8HTqe5tZh/bUrSHWSxk7oT4Kb2/cuB3YGfARcB9+wr1AQ4EnhWVX2y7yCStNBZ7KTu/BjYHzgX+E/gNUlWAy8EftFnsJ7dDPxX3yEkaQgWbXgTSWNyLM2oHcAbaK6MPYXmMOTL+wo1Af4GOKo9106SNAdePCH1KMn2wNW1Cf9DTPIF4NE0F5b8hN+8eOKQHmJJ0oLkiJ3UkSQfSnKn0WVVdRWwZZIP9RRrElwBfAb4Os3VwlfOeEiSNpIjdlJH2vPpdq2qy2Ys3xG4tKo851WSNCf+IpHmWXu4Ne1juySrRlYvBp5Mc49USZLmxGInzb8raOZmK5pzyGYq4OhOE02YJM8Dnsnst1q7ey+hJGkBsthJ8+8AmtG6rwNPA64aWXcrcEFVXdxHsEmQ5H8DrwU+SHMRxd/TzOv3aOCdPUaTpAXHc+ykjiTZG7hwU74CdjZJzgZeV1UnJrke2L+qzk3yRmCvqnphzxElacHwqlipO3cFHjL1QZLDk3w7yQeTbN1frN7tQTNhMzSTFW/Tvv9xmhFOSdJGsthJ3XkPzY3uSbIvzaHHM4CHA+/oL1bvLgV2bN+/gOb7Ac3hWEc3Jel2sNhJ3bkncGb7/tOAk6vqSJpbij2lt1T9+zowNQnxPwHvTnIK8Ema+e0kSRvJiyek7qyhmd4E4EDgpPb9S4Edekk0GY6g/SOzqo5LcjXwCODTNKOakqSN5MUTUkeSfBW4GDiZZmTq3lV1TpLHAB92Wg9J0lx5KFbqzlHAA4C/BY6tqnPa5c8AvtdTpt4l+bMkz5ll+XOSHNlHJklaqByxkzqQZBGwH810JzfMWLcMWF1VK3sJ17MkvwBeUFXfnLH8kTQjmffqJ5kkLTyO2EndKOBHtFfF3mZF1YpNtdS19qC5Gnami9p1kqSNZLGTOtBOSvwzYKe+s0ygS2kOUc/02zS3Y5MkbSSLndSdVwPvTPKAJOk7zAT5GPC+JAclWdo+Hk8z79+/9BtNkhYWz7GTOtLeLmsZzR9Uq4BbRtdX1Tazfd7QJVkK/DPwR8DqdvEi4FPAoZv4YWpJul0sdlJHkhy2vvVV9ZGuskyiJPdi7SHZH1XVz3uMI0kLksVOkiRpILzzhNShJLsAhwL3AN5YVVckeQRwcVWd12+67iR5H/DaqrqxfX+dquplHcWSpAXPYjcHSZ4LfLKqbpmxfDPgj6vqn/tJpkmU5EHA14DzgPsC76C56vMgYB/gWf2l69xvAUtH3l8XDylI0u3godg5SLIa2LWqLpuxfAfgsqpaPPtnalPU3tj+W1V1dHshxf5VdW6ShwOfqKq9O8iwFDgW+Luqmm3uOEnSAuZ0J3MTZh9R2Au4tuMsmnwPAma7QOISYJcuArRXmB5J89qVJA2Mh2LvgCRn0hS6Ar6ZZNXI6sXA3sCX+8imiXYzsN0sy/cDLptl+Xz5N+CxwIc63OdtJNnofVfV8+cziyQNicXujjmxfXs/4EvA6L0/bwXOBz7dcSZNvs8BRyd5RvtxJbkr8Da6fb18DfjrJPcHTgNuHF1ZVZ/pIMPMO3A8GlgDnNl+fD+aIwrf6iCLJA2G59jdQUmWAH8KfLaqfjUBeXarqov7zqF1S7INzUju/YGtaG6ltQvwHeBJVXXjej59nDnWrGd1dX1uaJLXAg8Enjf1PUiyFfBPwJlVdWyXeSRpIbPYzUGSFcB+VXX+BGRZA/wC+MbUw6I3mZI8luY+qIuA06vqqz1H6lWSS4ADq+onM5bfF/haVd2ln2SStPB4KHZu/hu4J82h177dC/id9vFWYI8kU0XvlKr6eG/JdBtV9XXg633nmCBbA7sBP5mxfFdgy+7jSNLcJNlrY7etqgvHum9H7O64JE+kKVFHM/u5Slf1kQsgyX40N51/DrDYqVf6keRNG7ttVf3lfGaZkuSVG8jx7i5yTElyAnAg8L+B77eLH0Zz7uEpVXV4l3kkaa7ao2gbVbDG/fvZYjcHM85VGv1Gho7PVUqyCFgOHEAzavcI4ErWHpbt7D6kSbanmSvtQGBnZkyrsynd7L69gnrU3jSjUFOHyXcDbgLOr6r7d5Rp5h0ultKMjt1MM//i3bvIMZJnC+BdwPNZO2nxKppz7F5VVTd1mUeS5qqdkH7KPsDbgeOA77XLHk5znv5rxn1EzWI3B0kes771VfXNDrNcB6wAvkhT5r7Z1wS0SU6iORn+eJoCc5sX2aZ6s/skzwOeCxw2NfTeDtd/GPiXqupz+pFd2hz/UFUn9ZRhK5pbrQGc09XFJJI0n5J8E3h/VZ04Y/nTgZdX1aPGuj+L3TAk+TbNiN05wCnt4xtVdWUPWa4DDqqqH3S970nWjpT9flX994zlDwA+18WdJ9YnyQOB/1dV9+pp/zvSFLsfzbxNnyQtVEluprnT0Nkzlu9D8//dWM8l9s4TY5BktyQPS/Lo0UeXGarqkTST374MuBo4CvhlkjOSvLfLLDST7d6wwa02PbsAW8yyfBmwY8dZZrOIju6AMSrJnZJ8iuZ1811g93b5cUmO6TqPJI3Z+TR3/JnpSGDsR9YcsZuDJLsBH6OZXLWYcYuxvi5YaA+rPRZ4MvCHdHzxRJI/avd7WFVZ8FpJPgfcHXgh8EOa18pDgA8C51XV73eU46kzF9GcY/cS4NyqenIXOUby/D2wf7v/bwP3b++h+7vAsVW1f5d5JGmckjwBOImmxE1dIPZQ4K7AU6vqX8e6P4vdHZfk/wE70PxC+iHwBJoRj78EXlFVJ3eY5Q9pLpo4gOZEzUtpZu3/Bs0h2Z91mOVMmhfsYpoX8srR9V1dJDBpkuxEc6/YJwCr28WLaG7xdVhVXd5RjpkTFBdwOc0ULH9eVZd0kWMkz0XAH1TVD5NcT3PI4twkU4dl79RlHkkatyR70IzQ7dcu+ilwXFX9ctz7ch67uXkM8OSqOitJAZdX1XeS3AL8FdBZsQPeA3yzfdtpkZvFiRveZNPTFrcntedVTP3jPmvmeRcd5Ji0UzC2o7mCe6Y7sbYAS9KCVVUXAa/rYl8Wu7nZAriiff8qmqk9zqaZaLXTUamq2q3L/a1PVf2fvjNMsrbIdVrmJtwPgUNo/iiBtacz/CnNOXeStKAl2RJ4ALNPATbW+3Nb7ObmLJqRl/OBHwEvSvJLmkOznd8/NsnmwLOB+9D8cvwJ8DGvMJwc7fmH65rf75AOczwZeA23fa28raq+3FWGEa8D/q29hdgS4JXt+w+hOX9VkhasJI8DPk5z6tZMRXPa0thM2iGZhea9wNR9LP8SeDxwLs1x9E6GXKckuQ/wc+DdNCdlPgz4G+DsJPfuOMtmSf5PkrOTrEiyevTRZZZJkuQdwEdpzj+8hubw4+ijqxx/QnMi7zk05e4vgPOAk5I8v6scU6rquzSTdW7WZjqQZv7Dh1fV6V3nkaQxey/wJWCPqlo04zH2Cxu9eGKM2qHW/YALq+qKDW0/5n2fTHMHg0Or6rp22TY0RWLzqjq4wyxvA/4IeAtNuXwDTZn5Y+CNVfXBrrJMkiS/Bl4yc5LKHnL8HHhvVf3tjOUvBV5aVft0mGUpzWv0dVV1Tlf7laSuJLmR5mr/Tv6Pc8RuDpK8qS1zAFTVTe0Iw4235x6hY/IIml+O143kuQ54PfDIjrP8IfCitsCtppl892U099Q9qOMsk2QRzSH7vu0FfGWW5f9Kc8uzzlTVSpqRbv/ClDRU3wH27WpnFru5ORrYepblW7brurQC2HaW5Xdu13VpF5pztqCZqHjb9v2v0PwS31QdDzyn7xDAhcxesB/PPEyWuRE+A8ycW0+ShuI44J1J/iTJQ5P89uhj3Dvz4om5uc2ExCMeSHOVbJe+APxDkheydgLEh9NMfvv5jrNcSHNz+wuBXwAHA6e1eW7uOMsk2RZ4VpKDgDP4zfn9XtZRjncC72//Q5m66vQRwKHASzvKMOpC4A1JHgWcCtzmHrFV9e4eMknSuEydfnP8LOvGfvGE59jdAe0kqgVsRXNe2+g3cTHNLaKOq6qXdJhpW5rJb5/C2rm/FgOfA55XVdd0mOUtwA1VdWx7k+OPAxfR3CrqHVX1+q6yTJIkp6xvfVUd0GGWPwD+HJi6sOanND+bz3WVYSTLeetZXVV1987CSNKYJVnvKS5VNdYjJRa7OyDJYTSjdR+iuSfrtSOrbwXOr6rv9RCNJPdk5Jd1Vf2ijxyjkjyUZkTo7Kr6Yt95NnVJPgv8I/Dlqpp5F4peJdkawFvRSRqSJE+kmQrt7sDBVfXLdoaC86rqa+Pcl4di74Cq+ghAkq2Ab1XVme3HBwGHAf+T5D+rqtOpPWabIy3JVOYu50g7FvhlVR3X7vsHwA+SvCjJX1XVG7vKMkmSrO+QeFXV73UU5Ubgk8C1SU4APtT3HwBJjgJeSTOqS5KLaabueU/516ekBSzJs2nOs/tHmt/RS9tVi4FXA2Mtdl48MTeHAvcFSLIn8Flge5pW/uYug0zKHGmtQ4H/mmX5acBzO84ySWb+TK4D7kYzCW9nP6OqejawK81t7x5HM9fht5I8N8kWXeWYkuTtwDE054Me1D6OA94EvK3rPJI0Zq8GXlhVrwBWjSz/Ps3dKMbKQ7FzkOQa4CFVdXaSVwCHVNUBSQ4APlxVd+0wy0TMkdZmWQHcp6rOnbH87sBPqmpZP8kmU5J3Adf1dSu29i4PfwK8CLiFZjTvPVX10472fxVwxMzXbnt+5gerarbZ2iVpQUhyE3DvqrqgPUd//6o6N8k9gB9X1Vj/oHbEbm4W05xTB83w6tTtmM6hmfKjS5MyRxo0Vzk+apblj6a5iEK39UGaUd7OJdkN+D3gd2n+kvw0sCdwRpJXdRjljHUs8/8oSQvdxcBsE78/mqYvjJX/ac7Nj4EXt9M0HMjaSV93Bzq98wSTM0caNEXlb5K8MMk92scRwLuY/XLvTV1nE1dCc7eHJE9P8mWaeet+H3g7sGtVvaCqngQ8jeaOIV34Z2Yvti8G/m9HGSRpvhwPvC/JI9qP92wvwnw78IFx78yLJ+bmNTTn1b0K+MjURRTAIcB/zvfOk7xv5MNFwLMnYI40qupdSXYE3kdz/09oRjbfW1Vvn+/9txcpPKeqrtvABQtdX1TyvpmLaM51eyLNFdZduaTd98eAv6iq2UbLvgVc3VGezWnm9zuYtXMwPpRmLsR/Gf2+dfk6nlRJfgrcq6r8/3sC+fOZfF3/jKrq7UnuDJxMMx3aKTSnvbyzqv5u3PvzhTcHVfWtJDsB21TV6C/BD9LMbzfffmvGxz9q3+43Y3nnJ1JW1WuTvBm4T7vopx1OYXEla7/mri8cWZ+ZP681wOXAK+i22L0C+FRVrfOOJO28h3frKM9+wOnt+1PzPV3aPu49sp0nBDf+DvC8w8nlz2fydf4zqqrXtzNG3IdmIOYn8/U70YsnJEmSBsJz7CRJkgbCYjdG7QUCE8EsszPL7CYly6TkALOsi1lmZ5bZTUqWSckB85/FYjdeE/PCwSzrYpbZTUqWSckBZlkXs8zOLLOblCyTkgPmOYvFTpIkaSC8eKK1WZbVsmw1p+dYWStYmrnfVGHNnbec83OsvOUGlm6+9ZyfJ6vn/vpYufJGli6d2/cWYNGKWze80QbcuuZmNls0x0m+x/RPZhxZVm2z+ViyrFpxI0uWze1nVIvHkOPmG1myxdxfK0tuWjPn5xjX6zar557l1tU3sdniuf+/sGrruU+EMK6f0eIrbpzzc6zkFpYy938DWTT3MY5bawWbzfH//3H9Ph7L76JxZRnHz6i95/mccozp9/M4vi/jet1ez9VXVNVOM5c73UlrWbbiYZs/se8YANz42Af0HWHaZtet2vBGHVn2P5Nx04oawy/qcbn6oHv0HWHaim0n5wDAzqd3NbPOhi2+9ua+I0y7/OE79h1h2vYnzPtUnxtt0RaTcZfDunXlhjfqSK2c+x/S45LNx/MH7DjUrZPzffnqmk9dMNvyyfmfWJIkSXNisZMkSRoIi50kSdJAWOwkSZIGwmInSZI0EBY7SZKkgbDYSZIkDYTFTpIkaSAsdpIkSQNhsZMkSRoIi50kSdJAWOwkSZIGwmInSZI0EBY7SZKkgbDYSZIkDYTFTpIkaSCW9B2gT0mOAI4AWMaWPaeRJEmam016xK6qjq+q5VW1fGmW9R1HkiRpTjbpYidJkjQkFjtJkqSBsNhJkiQNhMVOkiRpICx2kiRJA2GxkyRJGgiLnSRJ0kBY7CRJkgbCYidJkjQQFjtJkqSBsNhJkiQNhMVOkiRpICx2kiRJA2GxkyRJGgiLnSRJ0kAs6TvAxKiibr217xQAbPP9C/qOMO3so+7Wd4Rp9zpjTd8RAFhzzbV9R5i2/X9c1HeEaVcdv3nfEaYt/vT1fUdYa031nWDaTXfZqe8I07Zfs7rvCNPqllv6jgDA4p127DvCtFWXXNp3hGm1clXfEaZl8eK+I6y1jl+JjthJkiQNhMVOkiRpICx2kiRJA2GxkyRJGgiLnSRJ0kBY7CRJkgbCYidJkjQQFjtJkqSBsNhJkiQNhMVOkiRpICx2kiRJA2GxkyRJGoiJKnZJTkhyQt85JEmSFqKJKnaSJEm64yx2kiRJAzG4YpdkSd8ZJEmS+jC4Yges7DuAJElSHxZMsUtyaJKzk6xKclaSx6xj0wePfM7jkjx+Pc95RJJTk5y6klvGnlmSJKlLC6LYJdkROAH4EvBY4BTgA0kyc9uqOnXkw92BE9Z1eLaqjq+q5VW1fCmbjz+4JElShxZEsQNuAK4G9gEWA0dW1X2qqgCSvDjJwbN83jeAXYG9ugoqSZLUl4ktdkneOlXWqmoF8BDgcuAk4Iwko2XtWGDnWZ7msvbtbOskSZIGZSKLXZLtgNewtphRVedW1eHAbsCWwCtGPuXOwKWzPNU927ezrZMkSRqUiSx2wArgFmDP0YVJNgcOB/YGfjCy6lKawjfTs4Azq+r8eUkpSZI0QSZqzrd2RA6AJEcBH0vyXZrz6/YG7gf8Cji8qj4x8qkfBY5O8ivgdJqv65nAUcAhXWSXJEnq20QVu1FVdVySLwJPojn0+lng1Kr6+Sybvx7YHPgCsKxddibw9Ko6uYO4kiRJvZvUQ7EAVNVFwP8CrgHewjomH66qVVV1FLA98FvAnlV1/6r6UkdRJUmSejexI3YjjgGuB04DLl7fhlV1M/DjDjJJkiRNnIkvdiMXPlzZZw5JkqRJN9GHYiVJkrTxLHaSJEkDYbGTJEkaCIudJEnSQFjsJEmSBsJiJ0mSNBATP91JV1bvsBVXH/KwvmMAcOdzVvQdYdpe/35r3xHWqjV9J2hMSg6AVav6TjBt5Wf23PBGHUlu6DvCWltu3neCaSvuc3PfEbQ+my3tO8FEyqL0HWFaram+I2yQI3aSJEkDYbGTJEkaCIudJEnSQFjsJEmSBsJiJ0mSNBAWO0mSpIGw2EmSJA2ExU6SJGkgLHaSJEkDYbGTJEkaCIudJEnSQFjsJEmSBsJiJ0mSNBAWO0mSpIGw2EmSJA1EL8UuyUuSnJnkpiTbzvG5FiWxoEqSpE1e54UoycuBY4GPAr8LXD/Hp3xT+5AkSdqkLelhn88H3lxV74TpEbftq+qq9uPXAs8A7gHcCbgZuBT4RFW9fpbnO/6OBklyBHAEwGZbbXdHn0aSJGkizMuIXZJDk/wqydVJPpxk65HVlwFPaQ/Hfg64AXjf6KcD/wi8FbgSuAr4OnD2OnZ3JXDdyL6f2O73iiR/m+TO68pZVcdX1fKqWr5k2VZ36GuVJEmaFGMvdkl2Ak4APgU8DTgAGB1pexGwL/C3NCOGfwa8YWplVf018Iv2c44F7lpVL6yqj6xjlwcDFyZZ3H78buCLwOHAA4FTkmw5jq9NkiRpko31UGySR9MUukXA14DTgF8De7brFwH/BFwL/F5V/WCW59iG5vy7l1XVhzZitz8DtgN2Bi6hOYR7VFX9W5KTgcuBx9KUPUmSpMEa9zl27wcWA/8OnNS+fznw5+36Q4CHAvtW1YXreI7fA24FPgyQZA+AqrpoHdsva9/e2r69DDg8ya3A44GtgQvu4NcjSZK0YIz7UOx9gTdW1cHADu3He1XVt9v1+wL/vZ5SB7Ar8KuqqvbjP2kf6/Jk4MKqurL9+EjgATQjdAcAT6+qM+/IFyNJkrSQjHvEbjHNVaxU1bU0h1xH/RrYK8nmVXXLOp7jZ8B9k+xSVb+uqmPWtbMkU+fvTW9TVZ8HPn+HvwJJkqQFqut57D4LLAVObq9e3T3JnkmekuRj7TZfAs4FvprkkCQ7Jtkyyb5JXp5kryQHJfkEcDLNOX3v6vjrkCRJmjidFruqugZ4FHAN8BngIuBC4ETaiYqrahXNuXH/A3yS5hy9G4GzgNfSnC/3eWAr4ElVdXhVreny65AkSZpEYz0UW1XZiG3OAg5JshS4C828dRe3hW5qm0uBP06yGbA3zQUSFwNFc+7eeaPbS5IkqZ87TwBQVSuBX25gm1uBn89YfNW8hZIkSVrAOr9XrCRJkuaHxU6SJGkgLHaSJEkDYbGTJEkaCIudJEnSQFjsJEmSBqK36U4mzb13v5z//OsP9B0DgEe/+Ii+I0zb+qzJmV2mbl7Rd4SJUytX9h1h2s7fvqLvCNPWXHd93xGmLdp+u74jTNvyR1v0HWGtbHDa0+5kMsY46sab+o6gAZiMV7MkSZLmzGInSZI0EBY7SZKkgbDYSZIkDYTFTpIkaSAsdpIkSQNhsZMkSRoIi50kSdJAWOwkSZIGwmInSZI0EBY7SZKkgbDYSZIkDYTFTpIkaSAsdpIkSQNhsZMkSRoIi50kSdJAbNLFLskRSU5NcurlV67uO44kSdKcbNLFrqqOr6rlVbV8px0W9x1HkiRpTjbpYidJkjQkFjtJkqSB2CSKXZKPJHlJ3zkkSZLm0+CLXZJHAIcCX+47iyRJ0nwafLEDDgJSVef1HUSSJGk+Db7YVdUxVZW+c0iSJM23wRc7SZKkTYXFTpIkaSAsdpIkSQNhsZMkSRoIi50kSdJAWOwkSZIGwmInSZI0EBY7SZKkgbDYSZIkDcSSvgNMip9cvBPLj35x3zEAWLZkTd8Rpl3yuJ37jjBt169Pxg1E6ucTdHe6TM7fZpccuFPfEabt9rmb+44wrVbc0neEaUtvqL4jrDVBr90snpAsixf3nWAyTdD3JazuO8Ja64gyIa9mSZIkzZXFTpIkaSAsdpIkSQNhsZMkSRoIi50kSdJAWOwkSZIGwmInSZI0EBY7SZKkgbDYSZIkDYTFTpIkaSAsdpIkSQNhsZMkSRoIi50kSdJATGyxS3J4kvP7ziFJkrRQTGyxkyRJ0u1jsZMkSRqIBVnskixKsiCzS5IkzZeFWo7e1D7mJMkRSU5NcuqqFTeOIZYkSVJ/FmqxO759zCrJoUnOTrIqyVlJHjPbdlV1fFUtr6rlS5ZtNW9hJUmSutBZsWtHxx6xgW32TnJMkqUbeLorgevW8Rw7AicAXwIeC5wCfCBJbn9qSZKkhaOTYpdka+ADwKoNbLodcDSw/Qa2Oxi4MMniWdbdAFwN7AMsBo6sqvtUVd2+1JIkSQtLVyN2S9p9bb6uDZJsDrwe+BVw+Qae72c0JXDn9nPfmuRggKpaATykfY6TgDOS7DXXL0CSJGnSLeliJ1V1TZJPA59J8n7ge8DNwLbAvYD7A08ECnhGVa3ZwJHTZe3bW5NsB7wG+OTI/s4FDk+yJXAm8Ir2IUmSNFidFLvWM4GXtm9fRVPOrgHOpSlfrwI+U1Ubc3nqk4ELq+rKJFsAtwB7Av81tUE7Ang4sDfwg7F9FZIkSROqs2JXVSuBd7cP2osZUlVr1rH9CTQXQdxGkgNoDtke0253c5KjgI8l+S7N+XV7A/ejOax7eFV9YrxfjSRJ0uTpcsRupsOA36EZVVun9gKJ3YF9gRcATwc+CrxrapuqOi7JF4EnAVsCnwVOraqfz0NuSZKkidTnPHZfoB1124BDgQuAzwNbAU+qqsNnjvRV1UXA/6I5vPsWYOU4w0qSJE263kbsqupKmvnoNuTzNFOXnFdVG5ou5RjgeuA04OI5BZQkSVpg+jwUu1Gq6irgqo3c9vz23Y0pjJIkSYOyUG8pJkmSpBksdpIkSQNhsZMkSRoIi50kSdJAWOwkSZIGYuKviu3Ksh1XcM/Df9Z3DADO+uR+fUeYtvtJF/YdYdrqyy7vO8LkWbTeeyp3ardPn9t3hGlrrr6m7wjTsvcefUeYdvX+q/uOMG2nNZOTpVYv7jsCAFk9Od+TSbKBe8d3as0C+Bk5YidJkjQQFjtJkqSBsNhJkiQNhMVOkiRpICx2kiRJA2GxkyRJGgiLnSRJ0kBY7CRJkgbCYidJkjQQFjtJkqSBsNhJkiQNhMVOkiRpICx2kiRJA2GxkyRJGgiLnSRJ0kDcrmKXZMl8BZEkSdLc3N4Ru5XzkmIMkixJY3HfWSRJkvpwe4vdg6feSfK4JI9f14ZJHpzk20lWJrk0yUvvcMrm+bZNckySbdexyUrgMcDXbsdzHpHk1CSn3nL1irnEkyRJ6t3tKnZVderIh7sDJ6zn8Ow/AjcDBwFvBv46yd3W9/xJnpHkCSMf/0GS328/3BY4un1Lkicnee7Ipz8YOA3405HPT5LLkzxlHV/P8VW1vKqWb77dsvVFkyRJmngbLHZJXpzk4FlWfQPYFdhrHZ96EU352xX4p6q6U1Wdt4Hd3RM4auTjZwPPmLFNtW+PAXaZXlh1alVdX1U/G9l2C2ArYLMN7FeSJGnB25gRu2OBnWdZfln7dmeAJIclOWpk/R8DnwbeClw4etg2yd2SvHGW8+G+DzwyydTw2T40ZQ9g+/btVe3bJcCW6wqdZDPgHTRF8D/W+dVJkiQNxMZc5Xpn4NJZlk8Vrql1rwROmFpZVdcDb0zyJuCjwNuAf29XvwzYr6pWz3jOG2hG2N6X5DRgX2BRkpcD+wOnts8L8A/tdncBvgJc2Wa9F/DbwOOBpcDTq+oyJEmSBm5jit2lwG6zLH8WcGZVnd9+fA2w5+gGSQIc2D5OGln1MOBLszznPYGbgEfRHIY9GlhFc9j1YuCZUxtW1d8nuRg4EvgQTam7HjgfOAN4LXDiSBGUJEkatI0pdh8Fjk7yK+D09nOeSXMu3CEj270a+GKSRwDnAncB7ktzuPcDwF+NbLsdcMXoTpIsBV4BnFJVvzsjwztnC1ZVnwU+uxFfgyRJ0uBtTLF7PbA58AVg6ty3M2kOcZ48tVFV/aC96vUQmlJ3FfBj4L9mOeR6BvC8JD8Afk5zAcZbgP2AF93xL0eSJGnTtcFiV1WrgKOSvBa4B3BNVV20jm1vaC9auP/IslNn2fTVwKdoRgCnfBc4oKpOn2V7SZIkbcBG3yKsqm6mGYHbkC/QTIUCzTlvsz3X+cCDk2xPMyXKtVV14cZmkSRJ0m8a+71fq+pKmitUN2bbq1g7fYkkSZLm4PbeUkySJEkTymInSZI0EBY7SZKkgbDYSZIkDYTFTpIkaSAsdpIkSQMx9ulOFqrdl17DW/b4fN8xADjsgnv2HWHamh226TvCtFx1dd8RAKg11XeEtVat6jvBtFX32L3vCNMWXXtd3xGm5drJuV31Dqfu1HeEiZTFkzHGkS226DvCRKqaoP9zMxmvlfWZ/ISSJEnaKBY7SZKkgbDYSZIkDYTFTpIkaSAsdpIkSQNhsZMkSRoIi50kSdJAWOwkSZIGwmInSZI0EBY7SZKkgbDYSZIkDYTFTpIkaSAsdpIkSQNhsZMkSRoIi50kSdJAWOwkSZIGwmInSZI0EJt0sUtyRJJTk5x61VVr+o4jSZI0J5t0sauq46tqeVUt3377TfpbIUmSBsA2I0mSNBAWO0mSpIEYfLFL8mdJzuo7hyRJ0nwbfLEDdgT27TuEJEnSfBt8sauqY6oqfeeQJEmab4MvdpIkSZsKi50kSdJAWOwkSZIGwmInSZI0EBY7SZKkgbDYSZIkDYTFTpIkaSAsdpIkSQNhsZMkSRoIi50kSdJApKr6zjARtsn29dAc2HcMSZKkDfpqnXhaVS2fudwRO0mSpIGw2EmSJA2ExU6SJGkgLHaSJEkDYbGTJEkaCIudJEnSQFjsJEmSBsJiJ0mSNBAWO0mSpIGw2EmSJA2ExU6SJGkgLHaSJEkDMehil2R5kkpy176zSJIkzbdBFztJkqRNicVOkiRpICam2KXx6iTnJLk5yZlJntOuu2t7SPVpSU5OclOSnyQ5aMZzPCHJWUlWJPkPYJ9evhhJkqQeTEyxA94MvAB4CXAf4C3AB5M8eWSbY4H3AfsDPwQ+kWRrgCR7Ap8FTgYeALwfeHtH2SVJknq3pO8AAEm2Al4JPL6q/qNdfF6Sh9AUvSPbZX9TVV9oP+d1wHNpSty3gRcDFwIvq6oCzkqyD/BX69nvEcARAMvYctxfliRJUqcmotjRjNAtA76SpEaWLwXOH/n4jJH3L27f7ty+vTfw/bbUTfne+nZaVccDxwNsk+1rfdtKkiRNukkpdlOHhJ9CM+o2aiWQkfcBqKpKMvq5kiRJm7RJKXY/AW4B9q6qr89cuZHz0P0UeFqSjIzaPWx8ESVJkibbRBS7qro+yTuBd6YZhvsWsDVNMVsD/PtGPM1xwJ8D70ny98BvAS+ap8iSJEkTZ5IOY74ROAZ4FfA/NFe3Pg04b2M+uaouBJ4KPAH4b+AVwF/MR1BJkqRJlNtea7Dp2ibb10NzYN8xJEmSNuirdeJpVbV85vJJGrGTJEnSHFjsJEmSBsJiJ0mSNBAWO0mSpIGw2EmSJA2ExU6SJGkgLHaSJEkDYbGTJEkaCIudJEnSQFjsJEmSBsJiJ0mSNBAWO0mSpIGw2EmSJA2ExU6SJGkgLHaSJEkDYbGTJEkaCIudJEnSQFjsJEmSBsJiJ0mSNBAWO0mSpIGw2EmSJA2ExU6SJGkgLHaSJEkDYbGTJEkaCIudJEnSQFjsJEmSBsJiJ0mSNBAWO0mSpIFY0neAPiU5AjgCYBlb9pxGkiRpbjbpEbuqOr6qllfV8qVs3nccSZKkOdmki50kSdKQWOwkSZIGwmInSZI0EBY7SZKkgbDYSZIkDYTFTpIkaSAsdpIkSQNhsZMkSRoIi50kSdJAWOwkSZIGwmInSZI0EBY7SZKkgbDYSZIkDYTFTpIkaSAsdpIkSQORquo7w0RIcjlwwRyfZkfgijHEGQezzM4ss5uULJOSA8yyLmaZnVlmNylZJiUHjC/L3lW108yFFrsxSnJqVS3vOweYZV3MMrtJyTIpOcAs62KW2ZlldpOSZVJywPxn8VCsJEnSQFjsJEmSBsJiN17H9x1ghFlmZ5bZTUqWSckBZlkXs8zOLLOblCyTkgPmOYvn2EmSJA2EI3aSJEkDYbGTJEkaCIudJEnSQFjsJEmSBsJiJ0mSNBD/H8iFv1lsKuTaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-fault",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
